# 实验三 Map Reduce
* 班级：计科2003 
* 姓名：田沛骐
* 学号：2020014457
## 实验环境
1. Hadoop 2.7.1
2. Eclipse 4.8.0
3. CourseGrading 在线环境
4. 安装三个数据节点的Hadoop集群
## 实验内容与实验完成情况
### 实验准备
* 创建工作目录
```bash
mkdir -p ~/course/hadoop/mr_pro
cd ~/course/hadoop/mr_pro
```
* 安装部署Hadoop集群
```
 docker start master
 docker start slave1 
 docker start slave2 
 docker start slave3
 start-dfs.sh
 start-yarn.sh
 mr-jobhistory-daemon.sh start historyserver  
```
*  创建 eclipse 工程 启动 eclipse
*  建立 mr 项目。路径为
```
/headless/course/hadoop/mr_pro
```

* 准备测试数据 在终端下输入如下命令以建立测试数据，并上传至 hdfs。
* 建立测试数据 
```bash
cd ~/course/hadoop/mr_pro/WordCount/ 
mkdir target 
mkdir data 
cd data 
echo "Hello World" >> file1.txt 
echo "Hello MapReduce" >> file2.txt
```
* 数据上传至 hdfs 
```bash
docker exec -it --privileged master /bin/bash  hadoop fs -mkdir -p mapreduce/WordCount/input
cd /course/hadoop/mr_pro/WordCount/data 
hadoop fs -put file1.txt file2.txt 
mapreduce/WordCount/input  hadoop fs -ls 
mapreduce/WordCount/input
```
#### Word Count 
*  建立 Map 过程 
 Map 过程的建立主要在于重写 hadoop 的 Mapper 类的 map 方法，map 方法每次处理一行文本，多个节点进行 map，并将结果进行汇总。
 map 方 法中 value 为文本的一行，而 key 为这一行首字母相对于文本文件的首地址 的偏移量。
 对于 WordCount 这一问题，map 方法在于通过 StringTokenizer 类将 value 拆解成为一个一个 word 并组成 进行输出。
  ```java
protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException 
{
	String str = value.toString(); 
	String[] words = StringUtils.split(str," "); 
	for(String word : words){ 
		context.write(new Text(word), new 
		LongWritable(1)); 
	}
} 
```
#### Reduce 过程 
* Reduce 过程主要在于重写 Reducer 类中的 reduce 方法。在 Map 过程 中，其输出为多个单词键值对，reduce 的输入便是 map 的输出的一个分组，
 这样 reduce 只要遍历每个键值对并求和，就能完成 WordCount。 
  ```java
  protected void reduce(Text key, Iterable values,Context context) throws IOException, InterruptedException
   { long count = 0; 
   for(LongWritable value : values)
   { count += value.get(); } 
   context.write(key, new LongWritable(count)); }
  ```
#### MapReduce 执行
在 MapReduce 中，由 Job 对象负责管理和运行一个计算任务，并通过 Job 的一些方法对任务参数进行相关的设置。在采用前文中的 Mapper 和 Reducer 的同时，并将输入输出的类型进行了确定，并确定了数据的读入和 存放路径。 
``` java
public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
Configuration conf = new Configuration(); 
Job job = Job.getInstance(conf);  
job.setJarByClass(WcRunner.class); 
job.setMapperClass(WcMap.class); job.setReducerClass(WcReduce.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(LongWritable.class);  job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(LongWritable.class); FileInputFormat.setInputPaths(job, new Path(args[0]));  FileOutputFormat.setOutputPath(job, new Path(args[1])); 
job.waitForCompletion(true);
} 
```
#### 实验结果
通过 eclipse 打包后，进入 master 节点运行 
```bash
hadoop jar WordCount.jar mapreduce/WordCount/input mapreduce/WordCount/output 
```
实验结果如下图所示
![[Pasted image 20221208212655.png]]
